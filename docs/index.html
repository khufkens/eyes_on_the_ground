<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Processing of the Eyes on the Ground project • EotG</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="/apple-touch-icon.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="bootstrap-toc.css">
<script src="bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.1/css/all.min.css" integrity="sha256-PbSmjxuVAzJ6FPvNYsrXygfGhNJYyZ2GktDbkMBqQZg=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.1/css/v4-shims.min.css" integrity="sha256-A6jcAdwFD48VMjlI3GDxUd+eCQa7/KWy6G9oe/ovaPA=" crossorigin="anonymous">
<!-- Fonts --><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Titillium+Web:ital,wght@0,300;0,400;0,700;1,300;1,400&amp;display=swap" rel="stylesheet">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="pkgdown.js"></script><!-- ropensci --><link href="bglabs.css" rel="stylesheet">
<meta property="og:title" content="Processing of the Eyes on the Ground project">
<meta property="og:description" content="Wrapper package / project for the Eyes on the Ground
 project. This collaboration between IFPRI and LACUNA provides
 Machine Learning ground validation data collected through smartphone
 images at smallholder farmer's fields in Kenya. The package
 contains a few functions for anomyzing the raw data, as well as
 many more python components to screen the images for privacy related
 concerns (non-field images, or people in the field-of-view).">
<meta name="twitter:card" content="summary">
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-home">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">

    <div class="navbar-header">

      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="hidden-sm hidden-xs" href="https://bluegreenlabs.org">
          <img src="https://bluegreenlabs.org/img/logo_text_small.png" id="hexlogo" alt="bluegreen labs"></a>
        <a class="hidden-md hidden-lg" href="https://bluegreenlabs.org">
          <img src="https://bluegreenlabs.org/img/logo.png" id="hexlogo" alt="bluegreen labs"></a>
        <a class="navbar-brand" href="index.html">
           <i>EotG <small>v1.0</small></i>
        </a>
      </div>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
<li>
  <a href="index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
<li>
  <a href="https://twitter.com/bluegreen_labs">
    <span class="fab fa-twitter fa-lg"></span>
     
  </a>
</li>
        <li>
  <a href="https://github.com/khufkens/eyes_on_the_ground/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="contents col-md-9">
<div id="eyes-on-the-ground-" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#eyes-on-the-ground-" class="anchor"></a>Eyes on the ground <img src="logo.jpg" align="right" height="50">
</h1></div>
<div id="providing-quality-model-training-data-through-smartphone-images-of-crops" class="section level2">
<h2 class="hasAnchor">
<a href="#providing-quality-model-training-data-through-smartphone-images-of-crops" class="anchor"></a>Providing quality model training data through smartphone images of crops</h2>
<p>Processing code to create a unique dataset of at least 35,000 timestamped georeferenced crop images, along with various labels on input use, crop management, phenology, crop damage and yields.</p>
<p>This data will have valuable contributions in applications such as crop modeling, agricultural finance and insurance, agricultural advisories, and early warning systems.</p>
<div id="introduction" class="section level3">
<h3 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h3>
<p>This codebase serves two purposes, first provide a method to let data providers quickly screen for privacy issues of images collected in the field. Second, provide ancillary data with these images to support remote sensing applications.</p>
</div>
<div id="privacy-screening" class="section level3">
<h3 class="hasAnchor">
<a href="#privacy-screening" class="anchor"></a>Privacy screening</h3>
<p>Crop images are collected by farmers in support of insurance practices and crop monitoring. However, oversight, inexperience with digital technology can lead to situations where people’s private property or recognizable faces are present within a dataset which will be distributed widely and openly. This presents a clear privacy issue in violation with IRB requirements. Historically, manual screening was applied. However, with growing field trials this is not a long term solution. As such, an automated filter should relieve some of the burden.</p>
<p>Here, we use existing deep learning models to screen crops for non-vegetation images and human faces. Data allows for the screening of a single image or a whole directory of images (recursively parsed) with results returne as a CSV file for post-processing.</p>
<p>In our setup we use two common models to label both vegetation and faces. For the former we use a keras implementation of the PLACES365 VGG model, for the latter we use the MTCNN face recognition library.</p>
<p>The provided solution does not offer a retrained model specific to the circumstances of the field trials in order to scale flexibly. A trained model would be specific to a given field trial. Where accuracy might be higher, it would be less widely deployable compared to the unaltered model.</p>
<p>The output, which lists both the accuracy (%) and the original labels allows for post-processing and manual screening to remove remaining mislabelled images (and either classify them as either a privacy issue or not).</p>
</div>
<div id="ancillary-data-remote-sensing-data" class="section level3">
<h3 class="hasAnchor">
<a href="#ancillary-data-remote-sensing-data" class="anchor"></a>Ancillary data remote sensing data</h3>
<p>A second part of the processing requires amending seasonal image with ancillary remote sensing data. Remote sensing data will be stripped of geographic location data to provide anonymous but meaning full data for remote sensing analysis in conjunction with the original field based images. Data will be formatted as <a href="https://stacspec.org/">STAC compliant</a>.</p>
<p>Downloads of ancillary data are done using python code which taps into the Google Earth Engine back end. You can install the required package using <code>pip3 install gee-subset</code>. Check other requirements in the requirements.txt file as well. The code will run for specific locations and date ranges to be set manually. Final output will strip the data from spatial identifiers and list the pixel data (if there are multiple returns from top-left to bottom-right row wise).</p>
</div>
<div id="stac-processing" class="section level3">
<h3 class="hasAnchor">
<a href="#stac-processing" class="anchor"></a>STAC processing</h3>
<p>The above data is then compiled into a STAC catalogue, with the following structure. The focus here is on the image data, keeping the remote sensing data separate. The remote sensing data can however easily be merged to provide a consistent (machine learning) dataset. Note that no interpolation is done on the data products to retain the original data as much as possible. The latter is up to the user as many different interpolation strategies exist.</p>
<p><img src="stac_diagram.svg"></p>
</div>
</div>
<div id="data-sources" class="section level2">
<h2 class="hasAnchor">
<a href="#data-sources" class="anchor"></a>Data sources</h2>
<p>Polygons of villages were provided by the World Resource Insitute. Only labels are used and the original data needs to be downloaded from this location:</p>
<p><a href="https://datasets.wri.org/dataset/district-administrative-boundaries-of-kenya" class="uri">https://datasets.wri.org/dataset/district-administrative-boundaries-of-kenya</a></p>
<p>or sourced from the data directory of this project.</p>
</div>
<div id="acknowledgements" class="section level2">
<h2 class="hasAnchor">
<a href="#acknowledgements" class="anchor"></a>Acknowledgements</h2>
<p>This project is a collaboration between ACRE, IFPRI, CGIAR Big Data, and the Lacuna Fund.</p>
<div id="references" class="section level3">
<h3 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h3>
<ul>
<li><p>Places: A 10 million Image Database for Scene Recognition B. Zhou, A. Lapedriza, A. Khosla, A. Oliva, and A. Torralba (2017). IEEE Transactions on Pattern Analysis and Machine Intelligence</p></li>
<li><p>Joint face detection and alignment using multitask cascaded convolutional networks. Zhang, K., Zhang, Z., Li, Z., and Qiao, Y. (2016). IEEE Signal Processing Letters, 23(10):1499–1503.</p></li>
</ul>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <div class="links">
<h2>Links</h2>
<ul class="list-unstyled">
<li>Browse source code at <br><a href="https://github.com/khufkens/eyes_on_the_ground/">https://​github.com/​khufkens/​eyes_on_the_ground/​</a>
</li>
</ul>
</div>
<div class="license">
<h2>License</h2>
<ul class="list-unstyled">
<li><a href="https://www.r-project.org/Licenses/AGPL-3">AGPL-3</a></li>
</ul>
</div>
<div class="developers">
<h2>Developers</h2>
<ul class="list-unstyled">
<li>
<a href="https://bluegreenlabs.org">Koen Hufkens</a> <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0002-5070-8109" target="orcid.widget" aria-label="ORCID"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
</ul>
</div>

  </div>
</div>


      <footer><!-- begin footer --><div class="footer">
    <div class="container">
        <div class="row start bottom-8">
            <div class="col-xs-10">
                <div class="row">
                    <div class="col-md-4 col-xs-6">
                        <a href="http://github.com/bluegreen-labs" target="_blank">
                          <div class="icon fab fa-github"></div></a>
                        <a href="https://bluegreenlabs.org/labs/" target="_blank">
                          <div class="icon fa fa-flask"></div></a>
                        <a href="http://twitter.com/bluegreen_labs" target="_blank">
                          <div class="icon fab fa-twitter"></div></a>
                    </div>
                </div>
                <div class="row top-4">
                    <div class="col-md-2 col-sm-4">
                        <ul>
<h5 class="bottom-2">About</h5>
                            <li><a href="https://bluegreenlabs.org/#intro">BlueGreen Labs</a></li>
                            <li><a href="https://bluegreenlabs.org/#people">Our Team</a></li>
                            <li><a href="https://bluegreenlabs.org/#contact">Contact Us</a></li>
                        </ul>
</div>
                    <div class="col-md-2 col-sm-4">
                        <ul>
<h5 class="bottom-2">Resources</h5>
                            <li><a href="https://github.com/bluegreen-labs">Packages</a></li>
                            <li><a href="https://bluegreenlabs.org/publication/">Publications</a></li>
                            <li><a href="https://bluegreenlabs.org/post/">Blog</a></li>
                        </ul>
</div>

                </div>
            </div>
        </div>
    </div>
</div>
<!-- / end footer -->

      </footer>
</div>

  


  </body>
</html>
